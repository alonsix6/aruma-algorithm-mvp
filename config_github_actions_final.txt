name: Scrape Beauty Data - Aruma Algorithm

# Trigger del workflow
on:
  # Ejecutar cada hora en punto
  schedule:
    - cron: '0 * * * *'
  
  # Permitir ejecuciÃ³n manual desde GitHub Actions UI
  workflow_dispatch:
  
  # Ejecutar en push a main (opcional, para testing)
  # push:
  #   branches:
  #     - main

jobs:
  scrape-and-commit:
    name: Scrape data from all sources
    runs-on: ubuntu-latest
    
    steps:
      # 1. Checkout del cÃ³digo
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      # 2. Setup Python 3.10
      - name: ğŸ Setup Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
          cache-dependency-path: 'scrapers/requirements.txt'
      
      # 3. Setup Node.js 18
      - name: ğŸ“¦ Setup Node.js 18
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'scrapers/package-lock.json'
      
      # 4. Instalar dependencias Python
      - name: ğŸ“š Install Python dependencies
        working-directory: ./scrapers
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # 5. Instalar dependencias Node
      - name: ğŸ“¦ Install Node.js dependencies
        working-directory: ./scrapers
        run: |
          npm ci
      
      # 6. Crear directorios de datos si no existen
      - name: ğŸ“ Create data directories
        run: |
          mkdir -p data/trends
          mkdir -p data/tiktok
          mkdir -p data/meta
      
      # 7. Ejecutar scraper de Google Trends
      - name: ğŸ” Run Google Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "ğŸ” Scraping Google Trends..."
          python google_trends.py
        env:
          REGION: PE
        continue-on-error: true
      
      # 8. Ejecutar scraper de TikTok
      - name: ğŸµ Run TikTok Scraper
        working-directory: ./scrapers
        run: |
          echo "ğŸµ Scraping TikTok Creative Center..."
          node tiktok_scraper.js
        continue-on-error: true
      
      # 9. Ejecutar scraper de Meta
      - name: ğŸ“˜ Run Meta Graph API Scraper
        working-directory: ./scrapers
        run: |
          echo "ğŸ“˜ Scraping Meta Graph API..."
          node meta_scraper.js
        env:
          META_ACCESS_TOKEN: ${{ secrets.META_ACCESS_TOKEN }}
        continue-on-error: true
      
      # 10. Verificar archivos generados
      - name: ğŸ“Š Check generated files
        run: |
          echo "ğŸ“Š Verificando archivos generados..."
          ls -lah data/trends/ || echo "âš ï¸ No trends data"
          ls -lah data/tiktok/ || echo "âš ï¸ No tiktok data"
          ls -lah data/meta/ || echo "âš ï¸ No meta data"
      
      # 11. Commit y push de los datos
      - name: ğŸ’¾ Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "Aruma Algorithm Bot"
          
          # Agregar archivos de datos
          git add data/
          
          # Verificar si hay cambios
          if git diff --staged --quiet; then
            echo "âœ… No hay cambios en los datos"
          else
            # Commit con timestamp
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            git commit -m "ğŸ“Š Update data - $TIMESTAMP"
            
            # Push
            git push
            
            echo "âœ… Datos actualizados y pusheados"
          fi
      
      # 12. NotificaciÃ³n de Ã©xito
      - name: âœ… Success notification
        if: success()
        run: |
          echo "âœ… Scraping completado exitosamente"
          echo "â° PrÃ³xima ejecuciÃ³n: En 1 hora"
      
      # 13. NotificaciÃ³n de error
      - name: âŒ Error notification
        if: failure()
        run: |
          echo "âŒ Scraping fallÃ³"
          echo "ğŸ” Revisa los logs arriba para mÃ¡s detalles"